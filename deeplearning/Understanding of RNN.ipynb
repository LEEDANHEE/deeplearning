{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RNN의 기초적인 의사코드\n",
    "state_t = 0 # 초기 상태벡터\n",
    "for input_t in input_sequnece:\n",
    "    output_t = f(input_t, state_t)\n",
    "    state_t = output_t \n",
    "    \n",
    "##### 좀더 자세히 나타내자면\n",
    "state_t = 0 \n",
    "for input_t in input_sequence:\n",
    "    output_t = activation(dot(W, input_t)+dot(U, state_t)+ b)\n",
    "    state_t = output_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.42337284, 0.44713582])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random((2,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.55108285e-03 9.36741748e-01 7.45456769e-01 ... 9.82903665e-01\n",
      "  2.10940404e-01 7.80100732e-01]\n",
      " [6.39059559e-01 2.99515974e-01 4.85317719e-01 ... 4.88382874e-01\n",
      "  7.23117782e-01 9.36733156e-01]\n",
      " [2.91534146e-01 7.49268648e-01 6.86413795e-01 ... 8.74244303e-01\n",
      "  1.51420262e-02 5.11111681e-01]\n",
      " ...\n",
      " [9.87169190e-01 8.53194843e-01 1.57729333e-01 ... 9.83823541e-01\n",
      "  1.78793440e-01 8.20237368e-01]\n",
      " [2.77675907e-01 2.82778419e-01 4.33233905e-02 ... 5.09938985e-01\n",
      "  4.10544098e-04 4.61036984e-01]\n",
      " [9.25763339e-01 6.73488585e-01 1.74032407e-02 ... 4.03735712e-01\n",
      "  4.67699551e-01 3.29761083e-02]]\n",
      "[[0.72929661 0.04212517 0.11617315 ... 0.66653086 0.83010773 0.01143713]\n",
      " [0.09053887 0.36250886 0.44664435 ... 0.80479635 0.24411946 0.37247099]\n",
      " [0.27235309 0.67537683 0.86527018 ... 0.94133897 0.30673421 0.19378684]\n",
      " ...\n",
      " [0.61589283 0.59696451 0.11237675 ... 0.62919902 0.10977021 0.02693201]\n",
      " [0.20370251 0.32591445 0.99339398 ... 0.40793618 0.67299056 0.29455725]\n",
      " [0.45198609 0.66863834 0.31238101 ... 0.5747231  0.51070801 0.11169187]]\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "timesteps = 100\n",
    "input_features =32\n",
    "output_features = 64\n",
    "\n",
    "# 입력데이터 (난수) 100개의 타입스탭마다 input_features 개수 만큼의 벡터\n",
    "inputs = np.random.random((timesteps, input_features)) \n",
    "state_t = np.zeros((output_features))\n",
    "\n",
    "print(inputs)\n",
    "\n",
    "W = np.random.random((output_features, input_features))\n",
    "U = np.random.random((output_features, output_features))\n",
    "b = np.random.random((output_features,))\n",
    "print(W)\n",
    "successive_outputs = []\n",
    "for input_t in inputs:\n",
    "    output_t = np.tanh(np.dot(W, input_t) + np.dot(U, state_t) + b)\n",
    "    successive_outputs.append(output_t)\n",
    "    state_t = output_t\n",
    "    \n",
    "final_output_sequence = np.stack(successive_outputs, axis=0)\n",
    "\n",
    "print(len(final_output_sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 32)          320000    \n",
      "_________________________________________________________________\n",
      "simple_rnn_3 (SimpleRNN)     (None, 32)                2080      \n",
      "=================================================================\n",
      "Total params: 322,080\n",
      "Trainable params: 322,080\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import SimpleRNN, Embedding\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(10000, 32))\n",
    "model.add(SimpleRNN(32))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, None, 32)          320000    \n",
      "_________________________________________________________________\n",
      "simple_rnn_12 (SimpleRNN)    (None, None, 32)          2080      \n",
      "_________________________________________________________________\n",
      "simple_rnn_13 (SimpleRNN)    (None, None, 32)          2080      \n",
      "_________________________________________________________________\n",
      "simple_rnn_14 (SimpleRNN)    (None, None, 32)          2080      \n",
      "_________________________________________________________________\n",
      "simple_rnn_15 (SimpleRNN)    (None, 32)                2080      \n",
      "=================================================================\n",
      "Total params: 328,320\n",
      "Trainable params: 328,320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "25000 훈련 시퀀스\n",
      "25000 테스트 시퀀스\n",
      "시퀀스 패딩(Samples x time)\n",
      "input train 크기: (25000, 500)\n",
      "input test 크기: (25000, 500)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(10000, 32))\n",
    "model.add(SimpleRNN(32, return_sequences=True))\n",
    "model.add(SimpleRNN(32, return_sequences=True))\n",
    "model.add(SimpleRNN(32, return_sequences=True))\n",
    "model.add(SimpleRNN(32))\n",
    "model.summary()\n",
    "\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "max_features = 10000\n",
    "maxlen = 500\n",
    "batch_size = 32\n",
    "\n",
    "(input_train, y_train), (input_test, y_test) = imdb.load_data(num_words = max_features)\n",
    "print(len(input_train), '훈련 시퀀스')\n",
    "print(len(input_test), '테스트 시퀀스')\n",
    "\n",
    "print('시퀀스 패딩(Samples x time)')\n",
    "input_train = sequence.pad_sequences(input_train, maxlen=maxlen)\n",
    "input_test = sequence.pad_sequences(input_test, maxlen=maxlen)\n",
    "\n",
    "print('input train 크기:', input_train.shape)\n",
    "print('input test 크기:', input_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ktnet\\Anaconda3\\envs\\keras\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ktnet\\Anaconda3\\envs\\keras\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ktnet\\Anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\ktnet\\Anaconda3\\envs\\keras\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 28s 1ms/step - loss: 0.6410 - acc: 0.6111 - val_loss: 0.4929 - val_acc: 0.8006\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 27s 1ms/step - loss: 0.4068 - acc: 0.8269 - val_loss: 0.4518 - val_acc: 0.7934\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 28s 1ms/step - loss: 0.2923 - acc: 0.8819 - val_loss: 0.3294 - val_acc: 0.8664\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 27s 1ms/step - loss: 0.2268 - acc: 0.9132 - val_loss: 0.3790 - val_acc: 0.8480\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 27s 1ms/step - loss: 0.1718 - acc: 0.9376 - val_loss: 0.3536 - val_acc: 0.8758\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 27s 1ms/step - loss: 0.1275 - acc: 0.9560 - val_loss: 0.3683 - val_acc: 0.8642\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 27s 1ms/step - loss: 0.0835 - acc: 0.9732 - val_loss: 0.4132 - val_acc: 0.8620\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 27s 1ms/step - loss: 0.0529 - acc: 0.9841 - val_loss: 0.5840 - val_acc: 0.7820\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 27s 1ms/step - loss: 0.0341 - acc: 0.9904 - val_loss: 0.5064 - val_acc: 0.8638\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 27s 1ms/step - loss: 0.0282 - acc: 0.9918 - val_loss: 0.5553 - val_acc: 0.8384\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(SimpleRNN(32))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(input_train, y_train, epochs=10, batch_size = 128, validation_split=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 훈련 시퀀스\n",
      "25000 테스트 시퀀스\n",
      "시퀀스 패딩(Samples x time)\n",
      "input train 크기: (25000, 500)\n",
      "input test 크기: (25000, 500)\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 95s 5ms/step - loss: 0.4992 - acc: 0.7688 - val_loss: 0.3462 - val_acc: 0.8614\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 93s 5ms/step - loss: 0.2961 - acc: 0.8835 - val_loss: 0.2964 - val_acc: 0.8746\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 93s 5ms/step - loss: 0.2392 - acc: 0.9093 - val_loss: 0.3349 - val_acc: 0.8694\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 93s 5ms/step - loss: 0.2023 - acc: 0.9236 - val_loss: 0.3249 - val_acc: 0.8536\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 93s 5ms/step - loss: 0.1750 - acc: 0.9361 - val_loss: 0.2966 - val_acc: 0.8868\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 96s 5ms/step - loss: 0.1631 - acc: 0.9430 - val_loss: 0.3194 - val_acc: 0.8796\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 94s 5ms/step - loss: 0.1383 - acc: 0.9506 - val_loss: 0.3521 - val_acc: 0.8740\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 91s 5ms/step - loss: 0.1361 - acc: 0.9530 - val_loss: 0.4344 - val_acc: 0.8784\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 91s 5ms/step - loss: 0.1226 - acc: 0.9576 - val_loss: 0.3382 - val_acc: 0.8820\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 90s 5ms/step - loss: 0.1124 - acc: 0.9607 - val_loss: 0.3624 - val_acc: 0.8824\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "max_features = 10000\n",
    "maxlen = 500\n",
    "batch_size = 32\n",
    "\n",
    "(input_train, y_train), (input_test, y_test) = imdb.load_data(num_words = max_features)\n",
    "print(len(input_train), '훈련 시퀀스')\n",
    "print(len(input_test), '테스트 시퀀스')\n",
    "\n",
    "print('시퀀스 패딩(Samples x time)')\n",
    "input_train = sequence.pad_sequences(input_train, maxlen=maxlen)\n",
    "input_test = sequence.pad_sequences(input_test, maxlen=maxlen)\n",
    "\n",
    "print('input train 크기:', input_train.shape)\n",
    "print('input test 크기:', input_test.shape)\n",
    "\n",
    "from keras.layers import LSTM, Embedding, Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "history = model.fit(input_train, y_train, epochs=10, batch_size=128, validation_split=0.2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
